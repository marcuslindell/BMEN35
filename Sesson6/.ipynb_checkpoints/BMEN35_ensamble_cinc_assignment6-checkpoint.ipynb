{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/antfolk/BMEN35/blob/main/Sesson6/BMEN35_ensamble_cinc_assignment6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkiFi80bGKEc"
   },
   "source": [
    "# Assignment 6\n",
    "## Fill in your name below\n",
    "Marcus Lindell, BME18\n",
    "\n",
    "## Your mission is now the following:\n",
    "\n",
    "You will use data from the Computing in Cardiology challenge 2022 (as was explained in the lectures) (https://moody-challenge.physionet.org/2022/). The training set contains data from 942 patients. \n",
    "\n",
    "We have done some preprocessing of the data so you have features and labels for both **murmur** and **outcome**. The features include age, sex, weight, heigth, pregnancy status and mean, variance and skewness for the phonocardiogram at five different locations.\n",
    "\n",
    "Evaluate different ensamble methods (at least 3) from sklearn (https://scikit-learn.org/stable/modules/ensemble.html and https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble) and see how they perform on the CinC2022 challenge data. Take some time to read the documentation and see what options are available.\n",
    "\n",
    "As you may remember from the lecture there is quite an eloborate scoring scheme, however this is handled by the file cinc2022metric.py and the methods contained therein. \n",
    "\n",
    "**Also remeber you have two sets of labels!!! One set of labels for murmurs (Present, Unknown, Absent) and one for outcomes (Abnormal, Normal).**\n",
    "\n",
    "**Another thing you need to take into account is that the scoring functions need label probabilities of the predicted classes.**\n",
    "\n",
    "You will also need one-hot encoding of \"hard\" values for the training labels and for the test labels.\n",
    "\n",
    "We will start by uploading some files. You need to upload the files cinc2022metrics.py, feats.csv, murmur_labels.csv and outcome_labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRiQuM1OHKQR"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# _ = files.upload() # Upload the other files available in github under Session 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YbyBrB9MKBW"
   },
   "source": [
    "Next we will import some of the libraries/modules needed. (You will need to import others later on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SJx0_S_GMLfV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:51:50.922940: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import cinc2022metrics as cm # Our own little metrics file\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgS-HYV4MWn3"
   },
   "source": [
    "Next we will import data and the two different sets of labels and switch to numpy arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NXy1fcB8Mah0"
   },
   "outputs": [],
   "source": [
    "feats = pd.read_csv('feats.csv', header=None)\n",
    "murmur_labels = pd.read_csv('murmur_labels.csv', header=None)\n",
    "outcome_labels = pd.read_csv('outcome_labels.csv', header=None)\n",
    "\n",
    "feats = feats.to_numpy()\n",
    "murmur_labels = murmur_labels.to_numpy()\n",
    "outcome_labels = outcome_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6AjJag6bbYG"
   },
   "source": [
    "Here we will split the data and also define what the different classes for murmur and outcome are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DYFYliDGNCl0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_murmur, y_test_murmur, y_train_outcome, y_test_outcome = train_test_split(feats, murmur_labels, outcome_labels, test_size=0.2, random_state=0)\n",
    "murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "outcome_classes = ['Abnormal', 'Normal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AaRI3joNGvd"
   },
   "source": [
    "Next you can try out some of the available ensemble methods. Remember you need to predict probabilities for both classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FT0zGggANGIW"
   },
   "outputs": [],
   "source": [
    "# Do some imports (you now how to do this by now)\n",
    "from sklearn.ensemble import BaggingClassifier # Change questionmarks to something you want to test.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "y_test_murmur_bin = to_categorical(y_test_murmur)\n",
    "y_test_outcome_bin = to_categorical(y_test_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\n",
      "AUROC,AUPRC,F-meas,Accuracy,Weighted Accuracy,Cost\n",
      "0.549,0.367,0.307,0.709,0.654,13907.760\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.597,0.598,0.602,12244.691\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.547,0.559,0.541\n",
      "AUPRC,0.276,0.744,0.082\n",
      "F-measure,0.091,0.830,0.000\n",
      "Accuracy,0.050,0.971,0.000\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.648,0.648\n",
      "AUPRC,0.630,0.673\n",
      "F-measure,0.578,0.616\n",
      "Accuracy,0.605,0.592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_murmur = GradientBoostingClassifier()\n",
    "clf_outcome = GradientBoostingClassifier()\n",
    "\n",
    "clf_murmur.fit(X_train, y_train_murmur)\n",
    "clf_outcome.fit(X_train, y_train_outcome)\n",
    "\n",
    "y_pred_murmur_prob = clf_murmur.predict_proba(X_test)\n",
    "y_pred_outcome_prob = clf_outcome.predict_proba(X_test)\n",
    "\n",
    "murmur_scores, outcome_scores = cm.compute_scores(y_test_murmur_bin,   # One-hot encoded test labels for murmur eg. [1 0 0]\n",
    "                                                  y_pred_murmur_prob,  # One-hot encoded predicted probabilities for murmur eg. [0.1 0.7 0.2]                             \n",
    "                                                  murmur_classes,      # As defined before\n",
    "                                                  y_test_outcome_bin,  # One-hot encoded test labels for outcome eg. [1 0]\n",
    "                                                  y_pred_outcome_prob, # One-hot encoded predicted probabilities for outcome eg. [0.1 0.9]\n",
    "                                                  outcome_classes)     # As defined before\n",
    "\n",
    "cm.print_scores(murmur_scores, outcome_scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\n",
      "AUROC,AUPRC,F-meas,Accuracy,Weighted Accuracy,Cost\n",
      "0.536,0.368,0.315,0.704,0.652,14560.265\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.645,0.612,0.598,0.598,0.640,11456.735\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.532,0.525,0.551\n",
      "AUPRC,0.260,0.742,0.101\n",
      "F-measure,0.118,0.828,0.000\n",
      "Accuracy,0.075,0.956,0.000\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.645,0.645\n",
      "AUPRC,0.593,0.631\n",
      "F-measure,0.600,0.596\n",
      "Accuracy,0.663,0.544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf_murmur = BaggingClassifier()\n",
    "clf_outcome = BaggingClassifier()\n",
    "\n",
    "clf_murmur.fit(X_train, y_train_murmur)\n",
    "clf_outcome.fit(X_train, y_train_outcome)\n",
    "\n",
    "y_pred_murmur_prob = clf_murmur.predict_proba(X_test)\n",
    "y_pred_outcome_prob = clf_outcome.predict_proba(X_test)\n",
    "\n",
    "murmur_scores, outcome_scores = cm.compute_scores(y_test_murmur_bin,   # One-hot encoded test labels for murmur eg. [1 0 0]\n",
    "                                                  y_pred_murmur_prob,  # One-hot encoded predicted probabilities for murmur eg. [0.1 0.7 0.2]                             \n",
    "                                                  murmur_classes,      # As defined before\n",
    "                                                  y_test_outcome_bin,  # One-hot encoded test labels for outcome eg. [1 0]\n",
    "                                                  y_pred_outcome_prob, # One-hot encoded predicted probabilities for outcome eg. [0.1 0.9]\n",
    "                                                  outcome_classes)     # As defined before\n",
    "\n",
    "cm.print_scores(murmur_scores, outcome_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jf/997jgj615716tj_fk3sy40qh0000gn/T/ipykernel_21966/1862843092.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_murmur.fit(X_train, y_train_murmur)\n",
      "/var/folders/jf/997jgj615716tj_fk3sy40qh0000gn/T/ipykernel_21966/1862843092.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_outcome.fit(X_train, y_train_outcome)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\n",
      "AUROC,AUPRC,F-meas,Accuracy,Weighted Accuracy,Cost\n",
      "0.589,0.380,0.275,0.704,0.643,14560.265\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.644,0.638,0.608,0.608,0.621,11868.063\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.595,0.602,0.570\n",
      "AUPRC,0.248,0.787,0.104\n",
      "F-measure,0.000,0.826,0.000\n",
      "Accuracy,0.000,0.978,0.000\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.644,0.644\n",
      "AUPRC,0.638,0.638\n",
      "F-measure,0.593,0.622\n",
      "Accuracy,0.628,0.592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_murmur = RandomForestClassifier()\n",
    "clf_outcome = RandomForestClassifier()\n",
    "\n",
    "clf_murmur.fit(X_train, y_train_murmur)\n",
    "clf_outcome.fit(X_train, y_train_outcome)\n",
    "\n",
    "y_pred_murmur_prob = clf_murmur.predict_proba(X_test)\n",
    "y_pred_outcome_prob = clf_outcome.predict_proba(X_test)\n",
    "\n",
    "murmur_scores, outcome_scores = cm.compute_scores(y_test_murmur_bin,   # One-hot encoded test labels for murmur eg. [1 0 0]\n",
    "                                                  y_pred_murmur_prob,  # One-hot encoded predicted probabilities for murmur eg. [0.1 0.7 0.2]                             \n",
    "                                                  murmur_classes,      # As defined before\n",
    "                                                  y_test_outcome_bin,  # One-hot encoded test labels for outcome eg. [1 0]\n",
    "                                                  y_pred_outcome_prob, # One-hot encoded predicted probabilities for outcome eg. [0.1 0.9]\n",
    "                                                  outcome_classes)     # As defined before\n",
    "\n",
    "cm.print_scores(murmur_scores, outcome_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\n",
      "AUROC,AUPRC,F-meas,Accuracy,Weighted Accuracy,Cost\n",
      "0.527,0.414,0.344,0.704,0.646,14120.750\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.668,0.665,0.632,0.635,0.615,12106.918\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.477,0.515,0.589\n",
      "AUPRC,0.237,0.721,0.283\n",
      "F-measure,0.083,0.831,0.118\n",
      "Accuracy,0.050,0.956,0.077\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.668,0.668\n",
      "AUPRC,0.641,0.689\n",
      "F-measure,0.601,0.663\n",
      "Accuracy,0.605,0.660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_murmur = AdaBoostClassifier()\n",
    "clf_outcome = AdaBoostClassifier()\n",
    "\n",
    "clf_murmur.fit(X_train, y_train_murmur)\n",
    "clf_outcome.fit(X_train, y_train_outcome)\n",
    "\n",
    "y_pred_murmur_prob = clf_murmur.predict_proba(X_test)\n",
    "y_pred_outcome_prob = clf_outcome.predict_proba(X_test)\n",
    "\n",
    "murmur_scores, outcome_scores = cm.compute_scores(y_test_murmur_bin,   # One-hot encoded test labels for murmur eg. [1 0 0]\n",
    "                                                  y_pred_murmur_prob,  # One-hot encoded predicted probabilities for murmur eg. [0.1 0.7 0.2]                             \n",
    "                                                  murmur_classes,      # As defined before\n",
    "                                                  y_test_outcome_bin,  # One-hot encoded test labels for outcome eg. [1 0]\n",
    "                                                  y_pred_outcome_prob, # One-hot encoded predicted probabilities for outcome eg. [0.1 0.9]\n",
    "                                                  outcome_classes)     # As defined before\n",
    "\n",
    "cm.print_scores(murmur_scores, outcome_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGczxkWWR50z"
   },
   "source": [
    "Did you manage to comparable scores to those in the leaderboard as shown in the last slide of the lecture? (It should be noted that we don't have the validation data so we are perhaps comparing apples and oranges). Which set of ensemble classifiers worked the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__GradientBoosting__\n",
    "\n",
    "Murmur Weighted Accuracy: 0.654\n",
    "\n",
    "Outcome Cost: 12244.691\n",
    "\n",
    "\n",
    "__Bagging__\n",
    "\n",
    "Murmur Weighted Accuracy: 0.652\n",
    "\n",
    "Outcome Cost: 11456.735\n",
    "\n",
    "\n",
    "__RandomForest__\n",
    "\n",
    "Murmur Weighted Accuracy: 0.643\n",
    "\n",
    "Outcome Cost: 11868.063\n",
    "\n",
    "\n",
    "__AdaBoost__\n",
    "\n",
    "Murmur Weighted Accuracy: 0.646\n",
    "\n",
    "Outcome Cost: 12106.918\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lower half of the table for accuracy.\n",
    "\n",
    "In the upper half of the table for cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5zNz7eZeSvC"
   },
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO8UM1ZR7tIiAVsYf5/VFO4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
