{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbflMXxx6e/DslXNLmvEQC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antfolk/BMEN35/blob/main/Session5/BMEN35_Ex15_deep_neural_networks_part_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Neural Networks part 3\n",
        " \n",
        "In this notebook we will take a look \"under the hood\" of one our trained models. \n",
        "\n",
        "We will ... you know the drill."
      ],
      "metadata": {
        "id": "cwvBhcnH_82V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6qtJHyt_3qF"
      },
      "outputs": [],
      "source": [
        "# The usual imports\n",
        "from numpy import argmax\n",
        "from numpy import arange\n",
        "from numpy import transpose\n",
        "from numpy import array\n",
        "from numpy import concatenate\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "import time\n",
        "import numpy as np\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start by uploading our models from before."
      ],
      "metadata": {
        "id": "-FPgI1a-ATvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = files.upload() # Select all the model files (*.h5)"
      ],
      "metadata": {
        "id": "x5BfmyrqAbhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets first load one of our models"
      ],
      "metadata": {
        "id": "yjqii-elKEvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('model_b.h5')"
      ],
      "metadata": {
        "id": "NT4whZYxKHUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets remind ourselves of what the model looks like and investigate the convolutional layers."
      ],
      "metadata": {
        "id": "lsUsvn9B2XaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# investigate size of convolutional filters\n",
        "for layer in model.layers:\n",
        "  # check for convolutional layer\n",
        "  if 'conv' not in layer.name:\n",
        "      continue\n",
        "  # get filter weights\n",
        "  filters, biases = layer.get_weights()\n",
        "  print(layer.name, filters.shape)\n",
        "\n",
        "plot_model(model, show_shapes=True, show_layer_names=True, show_layer_activations=True) # "
      ],
      "metadata": {
        "id": "6hBhjMVnKyHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, lets visualise the 32 filter in the convolutional layer. They are all of size 3x3, only one color/channel."
      ],
      "metadata": {
        "id": "AJljvGp93YyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve weights from the first hidden layer\n",
        "filters, biases = model.layers[0].get_weights()\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "\n",
        "# plot first few filters\n",
        "n_filters, ix = 1, 1\n",
        "for i in range(32):\n",
        "    # get the filter\n",
        "    f = filters[:, :, :, i]\n",
        "    # plot each channel separately\n",
        "    for j in range(1):\n",
        "    # specify subplot and turn of axis\n",
        "        ax = plt.subplot(8, 4, ix)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    # plot filter channel in grayscale\n",
        "        plt.imshow(f[:, :, j], cmap='gray')\n",
        "        ix += 1\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cG3jMq1ZLCly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will load some images and see what happens"
      ],
      "metadata": {
        "id": "RSv57OuwLo2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = files.upload() # Select sample_image1.png and sample_image2.png"
      ],
      "metadata": {
        "id": "e0mulxvmLwZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = load_img('sample_image1.png', color_mode = \"grayscale\", target_size=(28, 28))\n",
        "img2 = load_img('sample_image2.png', color_mode = \"grayscale\", target_size=(28, 28))\n",
        "# plot the sample\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Image 1')\n",
        "plt.imshow(img1, cmap='gray')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Image 2')\n",
        "plt.imshow(img2, cmap='gray')\n",
        "plt.show()\n",
        "# convert to array\n",
        "img1 = img_to_array(img1)\n",
        "img2 = img_to_array(img2)\n",
        "# reshape into a single sample with 1 channel\n",
        "img1 = img1.reshape(1, 28, 28, 1)\n",
        "img2 = img2.reshape(1, 28, 28, 1)\n",
        "# prepare pixel data\n",
        "img1 = img1.astype('float32')\n",
        "img1 = img1 / 255.0\n",
        "img2 = img2.astype('float32')\n",
        "img2 = img2 / 255.0"
      ],
      "metadata": {
        "id": "XAvvoJ2wL-aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets start with using model c and see how this model performs. "
      ],
      "metadata": {
        "id": "3HoE6OvAOWFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('model_c.h5')\n",
        "predict_value1 = model.predict(img1)\n",
        "digit1 = argmax(predict_value1)\n",
        "predict_value2 = model.predict(img2)\n",
        "digit2 = argmax(predict_value2)   \n",
        "print('Predict image1 as: ', digit1)\n",
        "print('Predict image2 as: ', digit2)"
      ],
      "metadata": {
        "id": "A4ILCd1ROc4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets plot the full model so we remember what it looks like."
      ],
      "metadata": {
        "id": "6r-U8kiKRnLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, show_shapes=True, show_layer_names=True, show_layer_activations=True) # "
      ],
      "metadata": {
        "id": "zsxKfbeCRsl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will have a look at the model at different layers. We will start with after the first hidden layers."
      ],
      "metadata": {
        "id": "e8dfC1AfO6_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# redefine model to output right after the first hidden layer\n",
        "model = Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
        "feature_maps = model.predict(img1)\n",
        "print('Feature map size after first layer: ',feature_maps.shape)"
      ],
      "metadata": {
        "id": "XPWmfrRcPCiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot all 64 maps in an 8x8 squares\n",
        "ix = 1\n",
        "for _ in range(8):\n",
        "  for _ in range(4):\n",
        "    # specify subplot and turn of axis\n",
        "    ax = plt.subplot(8, 4, ix)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    # plot filter channel in grayscale\n",
        "    plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
        "    ix += 1\n",
        "# show the figure\n",
        "plt.show()  "
      ],
      "metadata": {
        "id": "HbBmRjW5PqNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets check the next layer. We will reload the model.\n"
      ],
      "metadata": {
        "id": "f4hrM5qySISV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload model\t\n",
        "model = load_model('model_c.h5')\n",
        "# redefine model to output right after the third hidden layer\n",
        "model = Model(inputs=model.inputs, outputs=model.layers[2].output)\n",
        "feature_maps = model.predict(img1)\n",
        "print(feature_maps.shape)\n",
        "# plot all 64 maps in an 8x8 squares\n",
        "ix = 1\n",
        "for _ in range(8):\n",
        "    for _ in range(4):\n",
        "        # specify subplot and turn of axis\n",
        "        ax = plt.subplot(8, 4, ix)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        # plot filter channel in grayscale\n",
        "        plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
        "        ix += 1\n",
        "# show the figure\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "ld7HDADXSLQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the layer after that."
      ],
      "metadata": {
        "id": "F5XHReErSnKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload model\t\n",
        "model = load_model('model_c.h5')\n",
        "# redefine model to output right after the fourth hidden layer\n",
        "model = Model(inputs=model.inputs, outputs=model.layers[3].output)\n",
        "feature_maps = model.predict(img1)\n",
        "print(feature_maps.shape)\n",
        "# plot all 64 maps in an 8x8 squares\n",
        "ix = 1\n",
        "for _ in range(8):\n",
        "    for _ in range(4):\n",
        "        # specify subplot and turn of axis\n",
        "        ax = plt.subplot(8, 4, ix)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        # plot filter channel in grayscale\n",
        "        plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
        "        ix += 1\n",
        "# show the figure\n",
        "plt.show()    "
      ],
      "metadata": {
        "id": "UVh_A_m_SsR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will check the final layers."
      ],
      "metadata": {
        "id": "cUWfsD1vT0ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload model\t\n",
        "model = load_model('model_c.h5')\n",
        "# redefine model to output right after the first hidden layer\n",
        "model = Model(inputs=model.inputs, outputs=model.layers[6].output)\n",
        "feature_maps6_1 = model.predict(img1)\n",
        "feature_maps6_2 = model.predict(img2)   \n",
        "\n",
        "# Reload model\t\n",
        "model = load_model('model_c.h5')\n",
        "# redefine model to output right after the first hidden layer\n",
        "model = Model(inputs=model.inputs, outputs=model.layers[7].output)\n",
        "feature_maps7_1 = model.predict(img1)\n",
        "feature_maps7_2 = model.predict(img2)\n",
        "\n",
        "# Plot the stuff\n",
        "plt.figure(figsize=(10, 8)) \n",
        "plt.subplot(2, 2, 1)\n",
        "plt.title('Output of layer 6 for image 1')\n",
        "plt.plot(concatenate(feature_maps6_1), 'b-')\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.title('Output of layer 6 for image 2')\n",
        "plt.plot(concatenate(feature_maps6_2), 'r-')\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.title('Output of layer 7 for image 1')\n",
        "plt.plot(concatenate(feature_maps7_1), 'bx')\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.title('Output of layer 7 for image 2')\n",
        "plt.plot(concatenate(feature_maps7_2), 'rx')   \n",
        "plt.show()  "
      ],
      "metadata": {
        "id": "zpMHMpxrT39z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does the last row of plots represent?\n",
        "\n",
        "# The End"
      ],
      "metadata": {
        "id": "KpnWX8Qv52Bi"
      }
    }
  ]
}