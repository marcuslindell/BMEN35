{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0CnDcBIISxBK1a9+mYflS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antfolk/BMEN35/blob/main/Session5/BMEN35_Ex16_deep_neural_networks_assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 5\n",
        "## Fill in your name below\n",
        "Alexander Andersson, BME4\n",
        "\n",
        "## Your mission is now the following:\n",
        "\n",
        "You will use a dataset named HAM10000 (\"Human Against Machine with 10000 training images\")  (https://doi.org/10.7910/DVN/DBW86T). The dataset contains dermatoscopic images from different populations, acquired and stored by different modalities. The final dataset consists of 10015 dermatoscopic images which can serve as a training set for academic machine learning purposes.  Cases include a representative collection of all important diagnostic categories in the realm of pigmented lesions: Actinic keratoses and intraepithelial carcinoma / Bowen's disease (akiec), basal cell carcinoma (bcc), benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, bkl), dermatofibroma (df), melanoma (mel), melanocytic nevi (nv) and vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc).\n",
        "\n",
        "More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal). \n",
        "\n",
        "For this exercise we have downsampled the images to 64x64x3 and randomly taken 1000 samples from the original 10015 to make training times more reasonable. Make sure you have downloaded the `HAM1000_64_64.zip` file from Github to your computer.\n",
        "\n",
        "\n",
        "We will start you off with loading the data and such."
      ],
      "metadata": {
        "id": "ezggec-uWg-6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0CWO-NpWavS"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "file = files.upload() # Choose HAM1000_64_64.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/HAM1000_64_64.zip -d /content/"
      ],
      "metadata": {
        "id": "T0SMhKTtYBPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have the data in our workspace. Lets do some imports.\n"
      ],
      "metadata": {
        "id": "ZgT7_nihWgJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input"
      ],
      "metadata": {
        "id": "Fwv_0oE-YbnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will read the data into Python."
      ],
      "metadata": {
        "id": "Kq7LuDBm-Met"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First read metadata into a dataframe\n",
        "base_dir = '/content/HAM1000_64_64/'\n",
        "skin_df=pd.read_csv(base_dir + 'dataframe.csv')\n",
        "# How many rows, that is how many images are there\n",
        "length = skin_df.shape[0]\n",
        "# Create a dictionary for the labels\n",
        "label_dict = {'nv': 0,'mel': 1,'bkl': 2, 'bcc': 3, 'akiec': 4,'vasc': 5,'df': 6 }\n",
        "# Recode labels in dataframe to be numbers\n",
        "skin_df['labels'] = skin_df['dx'].map(label_dict)\n",
        "#Allocate space for X and y aka our data and labels\n",
        "X = np.zeros((length,64,64,3))   \n",
        "y = np.zeros((length))\n",
        "k = 0\n",
        "for i in skin_df['image_id']: # Get filename from dataframe\n",
        "  #print(k)\n",
        "  X[k,:,:,:] = np.asarray(Image.open(base_dir +  i + '.jpg'))\n",
        "  k= k+1\n",
        "\n",
        "y = np.asarray(skin_df['labels'])  \n"
      ],
      "metadata": {
        "id": "p91MOT7NYdbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will do the usual conversion as before."
      ],
      "metadata": {
        "id": "Y5Zbv5kq-VOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to float and scale to be between 0 and 1\n",
        "X = X.astype('float32')\n",
        "X /=255.0\n",
        "yidx = y\n",
        "y = to_categorical(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state=0)"
      ],
      "metadata": {
        "id": "cc9qz1j3ahe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the data and visualise what kind of data we are dealing with."
      ],
      "metadata": {
        "id": "Gmy5WzlSY542"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 14)) \n",
        "plt.subplot(3, 3, 1)\n",
        "plt.title('Example of melanocytic nevi (nv)')\n",
        "plt.imshow(X[np.where(yidx == 0)[0][0], :, :])\n",
        "plt.subplot(3, 3, 2)\n",
        "plt.title('Example of melanoma (mel)')\n",
        "plt.imshow(X[np.where(yidx == 1)[0][0], :, :])\n",
        "plt.subplot(3, 3, 3)\n",
        "plt.title('Example of benign keratosis-like lesions (bkl)')\n",
        "plt.imshow(X[np.where(yidx == 2)[0][0], :, :])\n",
        "plt.subplot(3, 3, 4)\n",
        "plt.title('Example of basal cell carcinoma (bcc)')\n",
        "plt.imshow(X[np.where(yidx == 3)[0][0], :, :])\n",
        "plt.subplot(3, 3, 5)\n",
        "plt.title('Actinic keratoses and intraepithelial carcinoma (akiec)')\n",
        "plt.imshow(X[np.where(yidx == 4)[0][0], :, :])\n",
        "plt.subplot(3, 3, 6)\n",
        "plt.title('Example of vascular lesions (vasc)')\n",
        "plt.imshow(X[np.where(yidx == 5)[0][0], :, :])\n",
        "plt.subplot(3, 3, 7)\n",
        "plt.title('Example of dermatofibroma (df)')\n",
        "plt.imshow(X[np.where(yidx == 6)[0][0], :, :])\n",
        "plt.show() \n"
      ],
      "metadata": {
        "id": "uJ93BQlqZyMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, you have data X_train, X_test and labels y_train, y_test. Create a deep learning model (or use transfer learning on a pretrained model eg. VGG16 ), train it properly and make predictions using. You need get extract important metrics as well.\n",
        "\n",
        "To be clear you need to define the model and the metrics.\n",
        "\n",
        "Remember that this dataset is in color. That means your images has a \"depth\". Make sure you define this appropriately when you define your model. Keep in mind the number of classes/targets you have here.\n"
      ],
      "metadata": {
        "id": "iTDCM98Ie5MC"
      }
    }
  ]
}